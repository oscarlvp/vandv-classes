== Introduction

Software has become omnipresent in our daily lives. Some people say that "`software is eating the world`" <<andreessen2011why>>. Nowadays, we depend more and more on the Internet and the Web. They are powered by complex interconnected software systems. We trust software to predict the weather, to guard our bank accounts and to order pizza. Through software we communicate with other people and share our photos. We use streaming services to watch films and listen to music. 

Due to its widespread presence there are consequences when software is not properly developed. In some cases, a software failure has no other repercussion than a hilarious "blue screen of death" in an advertising screen. But, software issues may also cost important amounts of money, they may undermine the reputation of companies and, in some extreme cases, they might even cost human lives. 

We need to verify software, in other words, we need to check whether software works as expected. This course will briefly introduce some of the most relevant techniques and tools to achieve that goal. 

=== What is a bug?

We say that a software has a _bug_ when its behavior produces unexpected results. The term _bug_ has been usually attributed to Grace Hooper. She was involved in the programming and operation of the Mark II, an electromechanical computer of 23 tons and the size of a room. She was also the creator of the first compiler and the only woman to be ranked admiral in the U.S. Navy. Her group traced a computer malfunction to a moth in one of the relays of the machine. This is the first documented case of a computer "bug". The moth was included in one of the notebooks that were used to log the computer's operation. It can be seen nowadays at the Smithsonian Institution's National Museum of American History in Washington D.C <<img-bug>>. However, Thomas Alva Edison already used the term for something similar in his inventions <<wikipedia2020bug>>.

[[img-bug]]
[role=text-center]
.First known case of an actual bug! _Photo taken from Wikipedia._
image::first-bug.jpg[First bug, 300]

When they develop a product, software engineers should follow a set of requirements which is called the product specification. In whatever format it is presented, the specification should describe the features of the product (functional requirements): e.g.: the program should open a document, save it, etc. and its constraints (non-functional requirements): e.g.: should be secure, easy to use, fast <<mancoridis2018slides>>.

A bug appears when the software does not match the requirements. Maybe the program does not perform correctly a functional requirement _e.g._  the window closes when the maximize button is pressed. Also, bugs can make a program violate non-functional requirement _e.g._ there is a lag between the moment the user types something and the moment the text appears on the screen.

Bugs or _faults_ are produced by human mistakes in the development process. A fault induces a wrong state or _error_ during the execution of the software. When the error produces an incorrect behavior of the program we see a _failure_.

We define _faults_, _errors_ and _failures_ as follows <<moller1993empirical>>, <<ghahrai2018error>>, <<amman2017introduction>>:

Software Fault, Software Defect, Bug:: a manifestation of a human mistake in software. It is a static flaw or imperfection found within the code.
Software Error:: An incorrect internal state of the program during execution and produced by a _fault_. 
Software Failure:: a deviation of the software from its expected delivery or service.

A mistake leads to a fault, a fault leads to a software error which leads to a failure when the software is executed. A failure is the manifestation of a bug.

<<fault-example>> shows a recursive implementation of a binary search over an ordered array. Given an ordered array and a number, the `search` method returns the position of the number in the array or -1. The private overload of the method uses two auxiliary parameters to delimit the slice of the array that is inspected on each call. The initial slice is the entire array. When the method is invoked, it compares the element in the middle of the slice with the number given as input. If they are equal, then the position in the middle is returned, otherwise the method is invoked with the first half or the second half of the slice.
 

[[fault-example, Listing {counter:listing}]]
[source, java]
.Listing {listing}. Example of a bug or fault in a binary search implementation. The bug provokes an infinite recursion that leads to a stack overflow exception.
....
public static int search(int[] array, int element) {
  return search(array, element, 0, array.length - 1);
}

private static int search(int[] array, int element, int first, int last) {
  if(last < first) {
    return -1;
  }
  int middle = (first + last)/2;
  int median = array[middle];
  if(element == median) {
    return middle;
  }
  if(element < median) {
    return search(array, element, first, middle - 1);
  }
  return search(array, element, middle, last); //<1>
}
....
<1> The correct invocation should use `last + 1`.

This implementation has a fault. The second recursive invocation of search: `search(array, element, half, last)` should use `half + 1` instead of `half`. This fault does not always produce an error. For example, `search(new int[]{0, 6, 8, 10}, 6)` produces the right result. However, `search(new []{0, 6, 8, 10}, 10)`, leads to an invocation where `first=9` and `last=10`. For this invocation `middle=9` and once the comparisons are done, the same method is invoked again with the same parameters, this is the error produced by the initial fault. As method is invoked again with the same parameters, it produces an infinite recursion that is manifested through a stack overflow exception. This exception is the failure that evidences the initial fault. 

A failure may come from very different sources. Some of them could be traced to a very localized and specific part of the code, as in the example before. These are considered as _local bugs_. Others may be produced by the interaction of different components of the system and have a global scope. These are considered as _global bugs_. The following sections describe famous local and global bugs.

==== Local bugs and some famous cases

Local bugs can be traced to very specific locations in the code. They can be originated from multiple types of errors such as:

* Omission of potential cases _e.g._ not considering that negative numbers could be used in certain operations.
* Lacks of checks _e.g._ check if the parameter is `null` or the divisor must be other than zero.
* Wrong conditions _e.g._ using the wrong comparison operator.
* Wrong approximations _e.g._ wrong values due to type conversions or using the wrong partial results.

In the next sections we present some famous local bugs and briefly inspect their causes.

===== The case of Zune

_Zune 30_, was released to the public in November 2006. It was the first portable media player released by Microsoft. Suddenly, on December 31^st^ 2008, all Zune devices hung and stopped working. The problem was traced back to a piece of code in the firmware equivalent to <<zune-bug>>.

[[zune-bug, Listing {counter:listing}]]
.Listing {listing}. Bug in Zune 30
[source,java]
----
while (days > 365) {
    if (IsLeapYear(year)) { // <1>
        if (days > 366) {   // <2>
            days -= 366;    // <3>
            year += 1;      // <4>
        }
    }
    else {
        days -= 365;
        year += 1;
    }
}
----
<1> On December 31^st^, 2008 `year` was 2008 and `days` 366 so `isLeapYear(year)` evaluated to `true`.
<2> Since `days` was 366 `days > 366` evaluated to `false`. This is the fault, it should have been `>=`.
<3> This is not executed, therefore the value of `days` does not change.
<4> This is not executed, therefore the value of `year` does not change.

The values of `days` and `years` do not change which produced a wrong internal state and thus the error. The software enters an infinite loop and the devices become non-responsive.

By the next day, `days` would be 367 and the code would run perfectly. So Zune devices stop working on December 31^st^ of every leap year.

The issue was not on Microsoft's part. The code was written by another company for the clock chip. This bug is also an example of insufficient testing. Having tested the code with the right date, the bug could have been fixed before the release of the product.

===== Heartbleed

*Heartbleed* is a software vulnerability disclosed in April 2014 that granted attackers access to sensitive information. It was caused by a flaw in OpenSSL, an open source code library implementing the Transport Layer Security and Secure Sockets Layer protocols.

As part of these protocols, a computer should send a *heartbeat*, an encrypted message that the receiver should replay back, to keep the connection alive. The *heartbeat* contains information about its own length. The code for the receiver never verified that the message had the specified length. To answer, it should allocate a memory buffer to store the content of the *heartbeat*. If the message was longer, then there is a buffer overflow and the computer would send more data than requested <<fruhlinger2017what>>. 

The webcomic https://xkcd.com/[XKCD] explains this vulnerability in a very intuitive manner. See <<heartbleed-xkcd>>. 

[[heartbleed-xkcd]]
[.text-center]
.Heartbleed explanation by XKCD https://xkcd.com/1354/
image::heartbleed.png[Heartbleed, 400]

In <<heartbleed-source>> you can see a fragment of the code containing the bug.

[[heartbleed-source, Listing {counter:listing}]]
.Listing {listing}. Heartbleed source code
[source,c]
----
...
n2s(p, payload); // <1>
...
buffer = OPENSSL_malloc(1 + 2 + payload + padding); // <2>
bp = buffer;
...
memcpy(bp, pl, payload); // <3>
...
s->msg_callback(1, s->version, TLS1_RT_HEARTBEAT,  // <4>
	buffer, 3 + payload + padding,
	s, s->msg_callback_arg);
----
<1> Read payload length into `payload`.
<2> Allocate memory.
<3> Copy the payload and extra information as `payload` maybe larger than required.
<4> Send the data back.

===== Other interesting examples

The USS Yorktown (CG-48) cruiser was selected in 1996 as the testbed for the _Smart Ship_ program. The ship was equipped with a network of several 200 MHz Pentium processors. The computers abroad the ship ran Windows NT 4.0 and executed applications to run the control center, monitor the engines and navigate the ship. In September 21^st^ 1997 a crew member entered a zero into a database field causing a division by zero that resulted in a buffer overflow, which, in turn, made the propulsion system fail. The ship was dead for several hours and had to be towed back to port <<slabodking1998software>>.

The _Patriot_ missile defense system was able to track the trajectory of enemy projectiles and intercept them. The system stored the clock time in an integer that was converted to a fixed point number and multiplied by 1/10 to produce the time in seconds for the tracking estimation. The computation was performed in a 24-bit fixed point register and the time value was truncated. This would produce an error proportional to the uptime of the system (_i.e._ it grows in time). Apart from that, the system was updated several times to improve the conversion routine, but the patch was not placed in all the required code locations. On February 25^th^, 1991 one of these Patriot batteries failed to intercept an Iraqi Scud missile. The battery had been up for 100 hours and the chopping error was around 0.34 seconds. Since a Scud travels at 1.676 m/s it reaches more than a half kilometer in this time. The Scud struck an American Army barracks killing 28 soldiers and injuring around 100 other people <<arnold2000patriot>>.

The Chemical Bank deducted by error about $15 million from more than 100000 customers in one night. The problem was caused by a line of code that should not be executed until further changes were made to the system. This line sent a copy of every ATM transaction to the machine processing paper checks, so all transactions were deducted twice <<hansell1994glitch>>. 

==== Global bugs and famous cases

Rather than coming from a specific and localized error, some failures may emerge from the interactions of the modules that compose a system. This evidences that the whole is more than the mere sum of its parts.

Some sources of global bugs could be:

* Wrong assumptions about third party components.
* Errors in the reuse of code. For example, using the code in an environment or an architecture for which it was not designed.
* Concurrency bugs, that lead to race conditions and deadlocks by incorrectly assuming certain order of execution.
* Improbable or unforeseen interactions between hardware, software and users.

===== Race conditions and the Northeast blackout of 2003

A race condition appears when the output of a system depends on the sequence or timing of other uncontrollable events. This may lead to a bug when the effects of this assumption are not carefully considered. For example, in a multithreaded application, a piece of code may be (wrongly) assumed to run before another.

The code in <<race-condition>> shows a simplified example of a race condition.

[[race-condition, Listing {counter:listing}]]
.Listing {listing}. Example of race condition
[source,java]
----
public class SimpleApplet extends Applet {

    Image art;
    public void init() { // <1>
        art = getImage(getDocumentBase(), getParameter("img"));
    }

    public void paint(Graphics g) { // <2>
        g.drawImage(art, 0, 0, this); // <3>
    }

}
----
<1> `init` initializes `art`, if it is not invoked, then `art` is `null`.
<2> `paint` could be invoked before invoking `init`.
<3> If `paint` is invoked before `init` `art` is `null` which produces an error in this line.

To prevent this race condition, the code of `paint` should not assume that `art` will always point to an instance. To deal with this race condition it is enough to check if `art` is `null` or not.

On August 14^th^, 2003 the alarm of FirstEnergy, an electric utility in Akron, Ohio, should have alerted about an overload in the electricity transmission lines. A race condition stalled the alarm and the primary sever went down. A backup server started processing all demands and also went down after 13 minutes. With both servers down, the information being shown in the screens passed from a refresh rate of 1 to 3 seconds to 59 seconds. The operators were not aware of the actual condition of the grid and the system collapsed affecting an estimated of 50 million people.

WARNING: You may find an image circulating the Internet that is supposed to show a satellite view of this blackout. The image is in fact fake.

===== Ariane 5

The _Ariane 5_ test launch is one of the most referenced examples of the impact that a software bug can have. On June 4^th^ 1996, the rocket was launched by the European Space Agency from the French Guiana. After 40 seconds and at an altitude of more than 3700 meters the rocket exploded.

In <<jezequel1997design>> the authors explain that, before liftoff, certain computations are performed to align the Inertial Reference System (SRI). These computations should cease at -9 seconds from the launching sequence. But, since there is a chance that a countdown could be put on hold and because resetting the SRI could take several hours, it was better to let the computation proceed than to stop it. The SRI continues for 50 seconds after the start of flight mode. After takeoff this computation is useless. Yet they caused an exception which was not caught, and produced the explosion of the rocket.

Part of the software was reused from _Ariane 4_. It used 16-bit floating point numbers, while _Ariane 5_ used 64-bit. The conversion of a greater value caused the exception. The fact that this module used 16-bit floating point numbers was not documented in the code. The trajectory of _Ariane 5_ differed from that of _Ariane 4_. The former had considerably higher horizontal velocities that produced values above the initial range. This was the first launch after a decade of development with an estimated cost of $7 billion plus the rocket and cargo estimated in $500 million.

===== The Mars Climate Orbiter

The Mars Climate Orbiter probe crashed when entering the orbit of Mars. The cause was tracked to the fact that one development team was using the metric units and another team was using the Imperial Unit System. The loss was estimated in US$235.9 million <<ceguerra2001software>>. The subject is still inspiration of many memes cruel jokes.

=== Why is it so hard to build correct software?

Software inevitably fails. The causes for this are widely varied as we have seen from the previous examples. No domain related to software escapes from this fact. A failure can have multiple consequences even human lives. But why is it to hard to build correct software?

First of all, programs are very complex artifacts, even those we may consider simple or trivial.

Consider the code presented in <<collatz>>.

[[collatz, Listing {counter:listing}]]
.Listing {listing}. Will the alarm sound for all given inputs?
[source, java]
----
void alert(int n) {
  countdown(n);
  soundAlarm();
}

void countdown(int n) {
  while(n > 1) {
    if (n % 2 == 0)
      n = n /2;
    else
      n = 3 * n + 1;
  }
}
----

Is it possible to show that the alarm will sound for every value of `n`?
For this particular example one could attempt to devise a formal proof. But good luck with that! Mathematicians have been trying to do it since 1937 with no success. `countdown` is, in fact, an implementation of what is known as the link:https://en.wikipedia.org/wiki/Collatz_conjecture[Collatz  conjecture].

One could also try to verify the program for every possible input, but this is impossible in the general case.
For this particular example, let us assume that `n` is a 32-bits unsigned integer, then we have 2^32^ possible inputs, that is `4294967296` cases for a very simple code of barely 7 lines of code. If the computation of every input takes on average `2.78e-06` seconds, then we will spend 3 hours finding out the result, if the function stops for every input. 3 hours for barely 7 lines of code!

Determining if a procedure halts when given a specific input is known as the *Halting Problem* <<turing1936computable>>. The general case of this problem is undecidable. This means that, in general, we can not known for a given procedure if it will halt when processing a given input.

Let's prove it. Suppose that it is possible to write a function `halts` that tells whether a given function `f` halts when given an input `x`. That is, `halts` returns `true` if `f(x)` halts (<<halts-func>>) and `false` otherwise.

[[halts-func, Listing {counter:listing}]]
.Listing {listing}. A supposed function that, given a function `f` and an input `x` for `f`, returns `true` if the invocation of `f(x)` halts.
[source,javascript]
----
function halts(f, x):
    ...
----

If the `halts` function exists, then we can create a procedure, `confused`, that will loop forever if `halts` returns `true` (<<confused-proc>>).

[[confused-proc, Listing {counter:listing}]]
.Listing {listing}. A procedure that does not halt when `hatls(f, f)` is `true`, otherwise it does halt.
[source,javascript]
----
function confused(f) {
  if (halts(f, f)) //<1>
    while (true) {}
  else
    return false;
}
----

If we try to compute `confused(confused)`, `halts(f, f)` is equivalent to `halts(confused, confused)`. If this evaluates to `true`, then it means that `confused(consfused)` halts, but then the procedure enters in an infinite loop and so, in fact, `confused(confused)`, which is what we are evaluating in the first time, does not halt. On the other hand, if the condition is `false`, it means that `confused(confused)` does not halt, but then, the procedure halts.

Therefore, `confused(confused)` halts if and only if `confused(confused)` does not halt, which is a contradiction, so `halts` can not exist. This means that, in the general case, we can not prove that a program will halt when processing a given input. Of course, there are specific cases in which this is possible, but it can not be done for all existing procedures.

Proving the correctness of a program is a very difficult task. There are formal methods to try to achieve this, but they rely on mathematical models of the real world that might make unrealistic assumptions and, as abstractions, are different from the real machines in which programs execute.

Software is, of course, much more complex than the small functions we have seen so far. As an example, notice that the number of lines of code has increased exponentially in time (though not always in sync with the complexity of the task that the program should achieve), just take a look at the following <<loc>>:

[[loc,comparison]]
[#loc.text-center]
.Comparison in lines of code. Image taken from <<johnson2012curiosity>>
image::loc.jpg[Lines of code, 600]

The software of the Apollo 11 Guidance Computer had 145,000 lines of code, while NASA's Curiosity rover was programmed with 2.5M lines of code. The infamous Clippy on the other hand, had more than 100M lines of code.

Projects such as the Linux Kernel, have triplicated their size in 10 years:

[#kernel.text-center]
.Increment of lines of code in the Linux kernel.
image::kernel.png[LOCs Linux kernel, 600]

Firefox contains more than 36M lines of code and Chromium more than 18M. More statistics can be found link:https://www.openhub.net/[here]. 

The complexity of software does not come only from its size. For example, in both, Firefox and Chromium developers use more than 15 different programming languages at the same time.

Open source software also grows in complexity as the number of contributors increases. The Firefox project, for example, have had 6477 contributors and 996214 commits as of February 2018.

Also, most software is expected to run in multiple execution platforms, (including hardware, operating system, ...). Probably the most dramatic scenario in this sense comes from the mobile world. By August 2015 the OpenSignal company reported the existence of 24,093 different Android devices from 1294 distinct brands <<opensignal2015android>>. Android applications are expected to run correctly in all of them. 

Software is also present in systems with real-time computing constraints and sometimes implementing critical functionalities. For example, mp3 players, microwave ovens, GPS devices, medical equipment for vital sign monitoring, avionics (inertial guiding systems), automobiles, fire security systems and the list may go on. As a side note, a car nowadays contains more than 100M lines of code (mostly devoted to the entertainment system), and hundreds of electronic control units (ECU).

On top of that, software is not a static artifact that we release in production and leave as it is. It needs to be maintained over time. For example, Windows 95, was released to manufacturing on August 15^th^, 1995, it latest release was published on November 26^th^ 1997. However, its mainstream support ended on December 31^st^, 2000 while the extended support ended on December 31^st^, 2001, that is five and six years after its latest release. On its side, Windows 7 was released to manufacturing in July 22^nd^, 2009, support ended on January 14^th^, 2020 and the extended support for professional users should end on January 10^th^ 2023 while most of us are not using it nowadays.

The COBOL language appeared in 1959. It was estimated that, in 1997, around 80% of business transactions ran in COBOL. Even today, it is even said that more than 220 billions lines of COBOL are in use <<trikha2020inevitable>>. Migrating these legacy systems may be risky. In 2012 the Commonwealth Bank of Australia replaced its core banking platform to modernize their systems. The change ended up costing around 750 million dollars, which is why many banks have opted to keep their COBOL systems working. Today there are 75-, 60-years-old consultants providing support for COBOL systems in banks <<cnbc2017banks>>. In the recent Covid-19 crisis, the state of New Jersey in the U. S. requested COBOL programmers to deal with the 40-years old system to handle the huge amount of unemployment claims they received <<leswing2020bnew>>.
  
The software development process itself could be sometimes rather complex. There are many methodologies about how to build software, and they could even change during the creation of a new product.

So, the complexity of software may come from its requirements, its size as it can be huge, the number of technologies involved on its development as tens of languages and frameworks can be used at the same time, the number of people working on its implementation that could even be hundreds, the diversity of platforms in which it must run and even the development process.

=== How to build reliable software?

This is a difficult question and there is no easy answer. Systematically validating and verifying software as it is being built and maintained can lead to fewer bugs. *Verification* is the process in which we answer _Are building the product right?_, that is if the software conforms to its specification. *Validation* answers _Are we building the right product?_. In this sense  we check that the implemented product meets the expectation of the user _i.e._, whether the specification captures the customer's needs. 

There are three main general approaches to construct reliable software:

Fault-tolerance:: Admits the presence of errors and enhance the software with fault-tolerance mechanisms.
Constructive approach:: Involves formal modeling. It guarantees the reliability and correctness by construction.
Analytical approach:: Involves techniques to analyze the program in order to detect and fix errors.

==== Fault-tolerance

This approach assumes that it is impossible to prevent the occurrence of bugs in production. So, it enhances the system with mechanisms to deal with them.

_N-version programming_ is an example of this approach. With an initial and rigorous specification, two or more versions of the same system are developed by different development teams (usually with different backgrounds, and using different tools and methods to build the system). In production, these versions are executed in parallel. The actual output of the entire system is an agreement of the results obtained from all versions.

Another example is _Chaos engineering_ popularized by Netflix with its Simian Army. The main concept is to perform a controlled experiment in production to study how the entire system behaves under unexpected conditions. For example, in Netflix, they would simulate random server shutdowns to see how the system responds to this phenomenon <<netflix2011>>. This is a form of _testing in production_. Main challenges are to design the experiments in a way that the system does not actually fail and to pick the system properties to observe. In the case of Netflix, they want to preserve the availability of the content even when the quality has to be reduced.

Finally, approximate computing techniques <<mittal2016survey>> can be also applied to deal with a trade-off between accuracy and performance in a changing environment (_e.g._, time-varying bandwidth), when a _good enough_ result is better than nothing <<hardesty2010when>>. For example, Loop Perforation <<misailovic2010quality>>, which transforms loops to perform fewer iterations than the original loop, is used to keep the system running in a degraded environment, with a good enough result (e.g., dynamically adapting the video quality according to the actual bandwidth).

==== Constructive approach

This approach tries to guarantee the absence of bugs by construction. It involves the manual or automatic formal proof of all the components of the system, and their final integration. It is usually based on logical modeling and reasoning and it is used on specific parts of critical software.

The constructive approach may use tools such as link:https://coq.inria.fr/[Coq], a system to express assertions and mechanically check formal proofs or link:https://isabelle.in.tum.de/overview.html[Isabelle] an interactive theorem prover. <<coq-example>> shows how to use Coq to proof that the depth of any interior node in a tree is greater than 0.

[[coq-example, Listing {counter:listing}]]
.Listing {listing}. Small example of a proof achieved with the help of Coq. Taken from https://github.com/coq/coq/wiki/Quick-Reference-for-Beginners
[source,coq]
----
Module TreeExample.

  Inductive tree : Type := <1>
  | Leaf : tree
  | Node : tree -> tree -> tree
  .

  Check Node.

  Definition small_tree : tree := <2>
    Node (Node Leaf Leaf) Leaf.

  (* small_tree tree looks like:
          x
         / \
        x   x
       / \
      x   x
   *)

  Definition is_leaf (t : tree) : bool := <3>
    match t with
    | Leaf => true
    | Node x y => false
    end.

  Fixpoint depth (t : tree) : nat := <4>
    match t with
    | Leaf => 0
    | Node l r => S (max (depth l) (depth r)) (* Succesor of the  *)
    end.

  Lemma depth_positive : <5>
    forall t : tree, 0 < depth t \/ is_leaf t = true.
  Proof.
    induction t.
    { 
      cbv [depth is_leaf]. <6>
      right. <7>
      reflexivity. <8>
    }
    { 
      cbn [depth is_leaf]. <9>
      left. <10>
      lia. <11>
    }
  Qed.
----
<1> Definition of a tree type.
<2> Creating an instance of tree with three leaves and two intermediate nodes.
<3> Defining `is_leaf` which tells whether the given tree is a leaf or not.
<4> Defining a function to compute the depth of a leaf.
<5> Defining a lemma stating that the depth of a tree is positive when the tree is not a leaf.
<6> Inline definitions for `depth` and `is_leaf`.
<7> Set the right part of the disjunction as goal for the proof.
<8> The right part is true. This proves `true = true`.
<9> Inline again, but do not overwrite depth and is_leaf. This avoids recursive calls to `depth`.
<10> Set the left part of the disjunction as the goal.
<11> According to `depth`, the node can not be a leaf. So the second part of the `depth` definition is used.
<12> Inductive step. The successor of a natural number is always greater than 0.

The Coq system helps mechanizing the proof of lemmas and theorems by identifying the facts that can be used to achieve the proof and the formulas that still need to be proven.

Coq is also able to extract executable programs from definitions and theorems. There are additional extensions and tools to apply this methodology to other programming languages.

link:http://compcert.inria.fr/[CompCert] is the first formally verified C compiler, but it is not bug-free even when a lot of effort has been invested into its formal verification. As said before, the main problem with formal proofs comes from the assumptions they make to abstract the real world. The following quote explains the reason behind a bug found in _CompCert_:

[quote, https://news.ycombinator.com/item?id=11905706]
____
The problem is that the 16-bit displacement field is overflowed. CompCert’s PPC semantics failed to specify a constraint on the width of this immediate value, on the assumption that the assembler would catch out-of-range values. In fact, this is what happened. We also found a handful of crash errors in CompCert. 
____

Constructive approaches may also involve a form of model checking. These approaches represent the system as a formal behavioral model, usually transition systems or automata. The verification of these models is made with an exhaustive search on the entire state space. The specification of these models are written with the help of logic formalisms. The exhaustive search is directed to verify properties the system must have, for example, the absence of deadlocks. Model checking is used in hardware and software verification and, in most cases, they are performed at the system level. They find application in defense, nuclear plants and transportation.

The following diagram shows a model of the functioning of a microwave oven as a https://en.wikipedia.org/wiki/Kripke_structure_(model_checking)[Kripke structure]. (Adapted from https://www.dsi.unive.it/~avp/14_AVP_2013.pdf). The model includes first order propositions that characterize the states of the system and a transitional relationship between the states.

[graphviz, microwave, png]
.Model of a microwave-oven. Adapted from https://www.dsi.unive.it/~avp/14_AVP_2013.pdf 
....
digraph {

  node[shape=plain];
  rankdir = LR;

  s1[label=<<TABLE>
    <TR><TD> !START </TD></TR>
    <TR><TD> !CLOSE </TD></TR>
    <TR><TD> !HEAT  </TD></TR>
    <TR><TD> !ERROR </TD></TR>
  </TABLE>>];

  {
    rank = same;
    s2[label=<<TABLE>
      <TR><TD>  START </TD></TR>
      <TR><TD> !CLOSE </TD></TR>
      <TR><TD> !HEAT  </TD></TR>
      <TR><TD>  ERROR </TD></TR>
    </TABLE>>];
    s4[label=<<TABLE>
      <TR><TD> !START </TD></TR>
      <TR><TD>  CLOSE </TD></TR>
      <TR><TD>  HEAT  </TD></TR>
      <TR><TD> !ERROR </TD></TR>
    </TABLE>>];
    s3[label=<<TABLE>
      <TR><TD> !START </TD></TR>
      <TR><TD>  CLOSE </TD></TR>
      <TR><TD> !HEAT  </TD></TR>
      <TR><TD> !ERROR </TD></TR>
    </TABLE>>];
  }
  {
    rank = same;
    s5[label=<<TABLE>
      <TR><TD>  START </TD></TR>
      <TR><TD>  CLOSE </TD></TR>
      <TR><TD> !HEAT  </TD></TR>
      <TR><TD>  ERROR </TD></TR>
    </TABLE>>];
  s6[label=<<TABLE>
    <TR><TD>  START </TD></TR>
    <TR><TD>  CLOSE </TD></TR>
    <TR><TD> !HEAT  </TD></TR>
    <TR><TD> !ERROR </TD></TR>
  </TABLE>>];
  }
    s7[label=<<TABLE>
      <TR><TD>  START </TD></TR>
      <TR><TD>  CLOSE </TD></TR>
      <TR><TD>  HEAT  </TD></TR>
      <TR><TD> !ERROR </TD></TR>
    </TABLE>>];
  s1 -> s2 [label="start oven"];
  s1 -> s3 [label="close door"];
  s2 -> s5 [label="close door"];
  s3 -> s1 [label="open door"];
  s3 -> s6 [label="start oven"];
  s4 -> s1 [label="open door"];
  s4 -> s3 [label="done"];
  s4 -> s4 [label="cook"];
  s5 -> s2 [label="open door"];
  s5 -> s3 [label="reset"];
  s6 -> s7 [label="warmup"];
  s7 -> s4 [label="start cooking"];
}
....

These models can be used to generate concrete code that, for example, would be embedded in specific hardware, and it is possible to verify the state of the system at random inputs and even prove or falsify properties, _e.g._ for every input the heat is not on while the door is open. 

==== Analytical approach

This approach is directed to find the presence of bugs in the system. It is regularly based on heuristics and can target all kinds of software artifacts: code, models, requirements, etc. Its more used variant is *software testing* which evaluates a program by observing its execution under different conditions <<ammann2017introduction>>. Testing presents, nowadays, the best trade-off between effort and result when it comes to the verification and validation of a software product. It will be the main focus of this course.

Bertrand Meyer proposes seven principles of testing <<meyer2008seven>>:

Principle 1: To test a program is to try to make it fail:: This is the main purpose of testing, to find defects in the code. In the words of Meyer the _single goal_ of testing is _to uncover faults by triggering failures_. Testing can not be used to show the absence of bugs, as Dijkstra said and Meyer recalls. But it is extremely useful in finding those scenarios in which the software does not behave as intended. This definition of Meyer presents testing as a dynamic technique, that is, testing requires the execution of a program. However, there are some static code analysis techniques and tools that help detecting potential faults by finding well known code patterns that are prone to errors, or that ensure code quality by forcing development guidelines. In the long term these techniques help reducing the occurrence of bugs at a lower cost, since they don't execute the program. Some authors refer to these analyses as _static testing_. There is controversy on whether these static analyses are in fact testing or not, but since they are highly valuable for the quality of the software we shall discuss them in the course.
Principle 2: Tests are no substitute for specifications:: Tests are built from specific cases, instances of the different scenarios in which the software shall execute. The specification is composed of more general abstractions tied to human understanding. While the specification can be used to derive test cases the opposite is not necessarily true. Even in large numbers, a finite amount of tests may not capture the general properties of the system due to missing instances. 
Principle 3: Any failed execution must yield a test case, to remain a permanent part of the project’s test suite:: Once a fault has been discovered there is always the peril that it can reappear later. It happens often in practice. Uncovered faults should then become test cases that prevent these regressions. This is known as _regression testing_. 
Principle 4: Determining the success or failure of tests must be an automatic process:: Once a test is executed, one needs to know if the software behaved as expected. Thus, we need a _test oracle_ to produce such verdict. As the number of test cases grows, this task must be automated. It does not scale to run hundreds of test cases, print the output of the program and then manually check whether the output is correct.
Principle 5: An effective testing process must include both manually and automatically produced test cases:: Manually produced test cases come from the understanding developers have about the problem domain and the input, or from *Principle 3*, as Meyer explains. But often corner and specific cases escape from human intuition. Complementing manually designed test cases with automatically produced test cases can help spot what developers missed. Computers are able to generate test cases to a level that humans can not reach and help explore unforeseen scenarios.
Principle 6: Evaluate any testing strategy through objective assessment using explicit criteria in a reproducible testing process:: Any testing strategy must be assessed empirically. No matter how sophisticated a testing technique can be, it is of no use if it can not discover faults.  Meyer recalls that simple techniques such as random testing are proven to be quite efficient. Then there is the question on how to evaluate the effectiveness of our testing strategy.
Principle 7: A testing strategy’s most important property is the number of faults it uncovers as a function of time:: Code coverage, that is, the parts of the code executed in the test cases is often used to evaluate the quality of tests. However, this is only useful to spot the parts of the code that aren't yet tested, not how well the executed parts are verified. So, coverage is not, in general, a measure of the quality of the tests. The assessment of the tests should correspond to their ability to detect bugs. In this principle Meyer includes time. Of course, the faster faults are encountered, the better.

This set of principles is not comprehensive and not all authors and practitioners agree with all aspects of their formulations. However, in our opinion, they reveal the essence of testing.

NOTE: Meyer's article _Seven Principles of Software Testing_  provoked an answer from Gerald D. Everett, a testing expert and also author of books on the topic. The answer qualified Meyer's principles as _insufficient_ since they don't encompass other software quality aspects. The discussion went on with more answers and short essays from both authors. The entire discussion is worth the reading. More details and pointers can be found in Meyer's own blog: https://bertrandmeyer.com/2009/08/12/what-is-the-purpose-of-testing/. Needless to say, we agree with Meyer's point of view.

==== Modern practices: CI/CD and DevOps

Nowadays testing is automated as much as possible. Software developers use automated processes to facilitate the integration of the work done separately by team members, detect errors as fast as possible and automate most tedious and error-prone tasks.

*Continuous Integration* (CI) is one of those practices. It is a process in which developers frequently integrate their code into a single shared source control repository. After a change is pushed to a central repository, an automated pipeline is triggered to build and verify the application after the incorporation of the new change. <<fowler2006continuous>> <<thoughtworksintegration>>

According to Martin Fowler:

[quote, Martin Fowler, Chief Scientist ThoughtWorks]
____
Continuous Integration doesn’t get rid of bugs, but it does make them dramatically easier to find and remove.
____

The frequent integration of each developer's work facilitate the early detection of errors as opposed to each developer working on isolation and then spending a lot of time dealing with the combination of their individual efforts. Most software companies these days use a form of CI and the most used source control hosting services such as Github, Gitlab and Bitbucket encourage these practices by making it easy to incorporate CI tools and even providing their own CI automation alternatives.

According to Thoughtworks, <<thoughtworksintegration>> CI processes are supported by the following practices:

Maintenance of a single source repository:: All team members should merge their changes into a global/unique code repository, hosted in a source control hosting service, either in-premises or using a public service like Github. The source control repository plays an important role in the identification of a change and the detection of conflicts between simultaneous changes. The common practice nowadays is to use distributed source control systems like Git of Mercurial in opposition to the previous centralized systems like CVS or SVN. Even when the source control system is distributed, that is, every developer has a copy of the repository, the CI process should monitor one central repository to which all developers should push their changes. This does not exclude the creation of mirror repositories.

Automate the build:: Once a developer pushes her changes into the global repository, a CI server checks out the changes and triggers a build process. This build process is expected to be *self-testing*, that is, as part of the automated build, tests should be executed to verify the changes in the code. These tests should also be executed in an environment as *close* as possible *to* the *production conditions*. The build is also *expected to be fast* so developers have a quick feedback on the change they integrated and the outcome of the build process should be accessible to all team members so they know the current state of the project.

CI processes also impose responsibilities to developers as they are expected to push changes frequently. Also changes should be tested before integrating them into the global repository. Also, developers should not push any change while the automated build fails, that is, when a previous change produced a failure in the CI build process either compiling or running the tests. When a build fails it should be fixed as fast as possible to ensure the quality of the integrated code in the global repository.

CI processes are often accompanied by *Continuous Delivery* and *Continuous Deployment* processes.

*Continuous Delivery* is an automated process involving a verification pipeline whose outcome determines if a change is ready to be deployed. It may involve a larger build process than the one of the CI, including *acceptance tests*, which are tests in direct correlation to the requirements or the user's needs, tests in several environment conditions, such as different operating systems, and it may even include manual testing. Once a change passes the *delivery pipeline* it is considered as robust enough to be deployed.

On its side, *Continuous Deployment* is an automated process to set artifacts produced and verified by successful builds into production. Continuous Deployment requires Continuous Delivery. Both enable frequent product releases. Some companies may release their products in a daily or even an hourly basis.

CI/CD approaches find great realization in *DevOps*. DevOps is a modern development culture in which team members of all roles commit to the quality of the final product and not just divide themselves into silos like the "development team" or "operation team". Automation is at the core of DevOps as every development phase is backed by automated processes and state-of-the-art tools. In DevOps, all phases: _plan_, _code_, _build_, _test_, _release_, _deploy_, _operate_, _monitor_ are imbricated in an infinite loop (<<devops>>) and the outcome of one phase impacts the other. For example, crashes observed in production by monitoring the system, automatically become an issue for developers and are incorporated to the set of tests.

[[devops]]
[role=text-center]
.DevOps diagram
image::devops.svg[DevOps, 600]
